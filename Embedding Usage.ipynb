{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6805050f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9db41347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# installation\n",
    "# !pip install langchain\n",
    "# !pip install langchain_community\n",
    "# !pip install -U langchain-ollama\n",
    "# from langchain_community.embeddings.fastembed import FastEmbedEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a5d3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install fastembed\n",
    "# !pip install sentence-transformers\n",
    "# !pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a020caa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from fastembed import TextEmbedding\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcb6c273",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13401/1388450524.py:2: UserWarning: The model thenlper/gte-large now uses mean pooling instead of CLS embedding. In order to preserve the previous behaviour, consider either pinning fastembed version to 0.5.1 or using `add_custom_model` functionality.\n",
      "  embedder = TextEmbedding(model_name=\"thenlper/gte-large\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embedder = TextEmbedding(model_name=\"thenlper/gte-large\")\n",
    "# embedder = FastEmbedEmbeddings(model_name=\"thenlper/gte-large\")\n",
    "\n",
    "# List of sentences\n",
    "sentences = [\n",
    "    \"The cat is sitting on the mat.\",\n",
    "    \"A dog is playing in the garden.\",\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"A person is riding a bicycle.\",\n",
    "    \"It is raining outside.\"\n",
    "]\n",
    "\n",
    "# Generate embeddings\n",
    "sentence_embeddings = list(embedder.embed(sentences, batch_size=5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6233139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastembed.text.text_embedding.TextEmbedding at 0x7ca95c3c0d10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0daa727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_result(embedder,query):\n",
    "    \n",
    "    query_embedding = list(embedder.embed([query]))[0]\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarities = cosine_similarity([query_embedding], sentence_embeddings)[0]\n",
    "\n",
    "    # Find the index of the best match\n",
    "    best_index = int(np.argmax(similarities))\n",
    "    best_sentence = sentences[best_index]\n",
    "\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Best match: {best_sentence}\")\n",
    "    print(f\"Similarity score: {similarities[best_index]:.4f}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e5bed5",
   "metadata": {},
   "source": [
    "# Feel free to test customize the query/ add new sentence to in initial cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49ad7eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: A cat\n",
      "Best match: The cat is sitting on the mat.\n",
      "Similarity score: 0.8758\n"
     ]
    }
   ],
   "source": [
    "# Sentence to search\n",
    "query = \"A cat\"\n",
    "get_result(embedder,query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5350f4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Wish it rains\n",
      "Best match: It is raining outside.\n",
      "Similarity score: 0.8816\n"
     ]
    }
   ],
   "source": [
    "# Sentence to search \n",
    "query = \"Wish it rains\"\n",
    "get_result(embedder,query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ec0689",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
